{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a7d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import warnings\n",
    "import random\n",
    "import sqlalchemy\n",
    "from math import comb\n",
    "\n",
    "# Make sure these are in the filepath.\n",
    "import factorization\n",
    "import sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc8ef27",
   "metadata": {},
   "source": [
    "## Functions.\n",
    "These functions implement and evaluate the link prediction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be250175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove perc edges, for evaluation.\n",
    "# Does not mutate G.\n",
    "\n",
    "# DOES NOT WORK FOR DIRECTED GRAPHS.\n",
    "def remove_edges(G, perc=0.2):\n",
    "    \n",
    "    size = G.number_of_edges()\n",
    "    \n",
    "    # Num edges to remove.\n",
    "    N = np.floor(0.2*size)\n",
    "    \n",
    "    # Initialize output.\n",
    "    G_removed = G.copy()\n",
    "    removed_edges = []\n",
    "    bridges = []\n",
    "    j = 0\n",
    "    \n",
    "    while (len(removed_edges) < N) and (j < size):\n",
    "        \n",
    "        # Don't choose edges from the list of known bridges.\n",
    "        candidate_edges = list(set(G_removed.edges()) - set(bridges))\n",
    "        edge = random.choice(candidate_edges)\n",
    "        \n",
    "        # Check if the selected edge is a bridge.\n",
    "        G_removed.remove_edge(edge[0], edge[1])\n",
    "        is_bridge = not nx.has_path(G_removed, edge[0], edge[1])\n",
    "        \n",
    "        if is_bridge:\n",
    "            # If edge is a bridge, add it back to the graph and pass.\n",
    "            # Also add it to list of bridges so it isn't selected again.\n",
    "            G_removed.add_edge(edge[0], edge[1])\n",
    "            bridges.append(edge)\n",
    "        else:\n",
    "            # Otherwise, don't add the edge back and append it to output.\n",
    "            removed_edges.append(edge)\n",
    "        \n",
    "        j = j + 1\n",
    "    \n",
    "    # Return a new graph with edges remove, as well as what was removed.\n",
    "    return G_removed, removed_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fca6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates embeddings for G.\n",
    "def calc_embeddings(G, directed=False, alg=\"factorization\", sim=\"autocovariance\"):\n",
    "    # G -- nx.Graph, or nx.DiGraph (if directed==True)\n",
    "    # Directed -- t/f\n",
    "    # alg -- embedding algorithm -- \"factorization\", \"sampling\"\n",
    "    # sim -- similarity metric -- \"autocovariance\", \"PMI\"\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    if alg == \"factorization\":\n",
    "        \n",
    "        # factorization.embed(G, dimensions=128, markov_time, directed, similarity, average_similarity)\n",
    "        emb = factorization.embed(G, 128, 3, directed, sim, False)\n",
    "        \n",
    "    elif alg == \"sampling\":\n",
    "        \n",
    "        # sampling.embed(G, dimensions=128, markov_time, None, directed, similarity, average_similarity,\n",
    "        #       lr, iter, early_stop, batch_size, neg, walks, walk_length, damp, workers)\n",
    "        emb = sampling.embed(G, 128, 3, None, directed, sim, False,\n",
    "                            6e-3, 50, 5, 100, 1, 10, 80, 0.85, 32)\n",
    "        \n",
    "    return emb[:, ~np.isnan(emb).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b83bf9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of embeddings, return a list of top k predicted edges.\n",
    "def link_prediction(G, emb, k):\n",
    "    \n",
    "    existing_edges = [(min(edge), max(edge)) for edge in G.edges()]\n",
    "    vertices = sorted(list(G.nodes()))\n",
    "    \n",
    "    candidate_edges = [(u, v) for u in vertices for v in vertices]\n",
    "    candidate_edges = [edge for edge in candidate_edges if\n",
    "                       (edge[0] < edge[1])]\n",
    "    candidate_edges = [edge for edge in candidate_edges if\n",
    "                       (edge not in existing_edges)]\n",
    "    \n",
    "    dic = {}\n",
    "    for j in range(len(vertices)):\n",
    "        dic[vertices[j]] = emb[j, :]\n",
    "        \n",
    "    # I'm not sure if this should be sorted by asc or desc.\n",
    "    predictions = sorted(candidate_edges,\n",
    "                         key=lambda x: np.dot(dic[x[0]], dic[x[1]]), reverse=True)\n",
    "    \n",
    "    return predictions[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69cf08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do everything: Remove edges, link prediction, and evaluate.\n",
    "def eval_model(G, k, get_all_preds=False):\n",
    "    G_removed, removed_edges = remove_edges(G)\n",
    "    order = len(G_removed.nodes())\n",
    "    size = len(G_removed.edges())\n",
    "    \n",
    "    # If this is true, return the whole list of predictions rather than the confusion matrix.\n",
    "    if get_all_preds:\n",
    "        k = comb(order, 2) - size\n",
    "    \n",
    "    # Make predictions.\n",
    "    emb = calc_embeddings(G_removed)\n",
    "    predictions = link_prediction(G_removed, emb, k)\n",
    "    \n",
    "    if get_all_preds:\n",
    "        return predictions\n",
    "            \n",
    "    # Evaluate against removed_edges.\n",
    "    removed_edges = [(min(edge), max(edge)) for edge in removed_edges]\n",
    "    TP = len([edge for edge in predictions if (edge in removed_edges)])\n",
    "    FP = len(predictions) - TP\n",
    "    FN = len(removed_edges) - TP\n",
    "    TN = comb(order, 2) - size - TP - FP - FN\n",
    "            \n",
    "    return (TP, FP, FN, TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7a47d",
   "metadata": {},
   "source": [
    "## Experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f92b256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for METIS clustered short graph: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Experiments for shortened graph.\n",
    "\n",
    "# Total number of prediction is k * #Clusters. In this case, 5*5 = 25.\n",
    "k = 5\n",
    "TP = 0\n",
    "TF = 0\n",
    "\n",
    "for j in range(5):\n",
    "    path = \"metis_graphs/G_short_partitions/G_short_partition\" + str(j) +\".pk\"\n",
    "    with open(path, \"rb\") as file:\n",
    "        subgraph = pickle.load(file)\n",
    "    CMatrix = eval_model(subgraph, k=k)\n",
    "    TP = TP + CMatrix[0]\n",
    "    TF = TF + CMatrix[1]\n",
    "\n",
    "prec = TP/(TP+TF)\n",
    "print(\"Precision for METIS clustered short graph: \" + str(prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ef1efc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for METIS clustered full graph: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Experiments for full graph.\n",
    "# This takes many hours!!\n",
    "\n",
    "# Total number of prediction is k * #Clusters. In this case, 5*10 = 50.\n",
    "k = 5\n",
    "TP = 0\n",
    "TF = 0\n",
    "\n",
    "for j in range(10):\n",
    "    path = \"metis_graphs/G_full_partitions/G_full_partition\" + str(j) +\".pk\"\n",
    "    with open(path, \"rb\") as file:\n",
    "        subgraph = pickle.load(file)\n",
    "    CMatrix = eval_model(subgraph, k=k)\n",
    "    TP = TP + CMatrix[0]\n",
    "    TF = TF + CMatrix[1]\n",
    "\n",
    "prec = TP/(TP+TF)\n",
    "print(\"Precision for METIS clustered full graph: \" + str(prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79252060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL PREDICTIONS FOR FULL GRAPH.\n",
    "# This cell also takes a while!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
